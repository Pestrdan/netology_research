{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pestrdan/netology_research/blob/main/Deep_learning_(Pytorch)/DLL_35_HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB1QEk1gm1oW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # для работы с данными\n",
        "import time  # для оценки времени\n",
        "import torch  # для написания нейросети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3aOx64Mm1oZ"
      },
      "source": [
        "## Загрузка данных\n",
        "\n",
        "Будем работать с датасетом реплик из Симпсонов. Нам нужно извлечь предобработанные тексты и закодировать их числами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duHW4TnGm1ob",
        "outputId": "24eed3a8-afef-4a52-e94f-f0e5c8a122d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-40135c10baa1>:1: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('simpsons_script_lines.csv')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('simpsons_script_lines.csv')\n",
        "#df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L92hozwK8H9O"
      },
      "outputs": [],
      "source": [
        "#df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjSdDLcSm1oc"
      },
      "outputs": [],
      "source": [
        "phrases = df['normalized_text'].tolist()  # колонка с предобработанными текстами\n",
        "#phrases[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ChXCEWwm1od"
      },
      "outputs": [],
      "source": [
        "text = [[c for c in ph] for ph in phrases if type(ph) is str]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wEaD3InZ-dB"
      },
      "source": [
        "# **Задание 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAQEsntvm1od"
      },
      "source": [
        "## Создаём массив с данными\n",
        "\n",
        "Нужно\n",
        "\n",
        "1. Разбить данные на токены (у нас символы)\n",
        "2. Закодировать числами\n",
        "3. Превратить в эмбеддинги"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfE9RtIAN4HM"
      },
      "outputs": [],
      "source": [
        "CHARS = set('abcdefghijklmnopqrstuvwxyz')\n",
        "INDEX_TO_CHAR_PRE = [w for w in CHARS]\n",
        "INDEX_TO_CHAR_PRE.sort()\n",
        "INDEX_TO_CHAR = ['none'] + [' '] + INDEX_TO_CHAR_PRE\n",
        "CHAR_TO_INDEX_Y = {w: i for i, w in enumerate(INDEX_TO_CHAR)}\n",
        "#CHAR_TO_INDEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9xSfE4PPix8"
      },
      "outputs": [],
      "source": [
        "step = 3\n",
        "CHAR_TO_INDEX_X = {}\n",
        "for key, value in CHAR_TO_INDEX_Y.items():\n",
        "  CHAR_TO_INDEX_X[key] = value + step\n",
        "#CHAR_TO_INDEX_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8_Kqpjnm1oe"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 50  # мы хотим ограничить максимальную длину ввода\n",
        "X = torch.zeros((len(text), MAX_LEN), dtype=int)  # создаём пустой вектор для текста, чтобы класть в него индексы токенов\n",
        "for i in range(len(text)):  # для каждого предложения\n",
        "    for j, w in enumerate(text[i]):  # для каждого токена\n",
        "        if j >= MAX_LEN:\n",
        "            break\n",
        "        X[i, j] = CHAR_TO_INDEX_X.get(w, CHAR_TO_INDEX_X['none'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZA5k9mrQSqa"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 50  # мы хотим ограничить максимальную длину ввода\n",
        "Y = torch.zeros((len(text), MAX_LEN), dtype=int)  # создаём пустой вектор для текста, чтобы класть в него индексы токенов\n",
        "for i in range(len(text)):  # для каждого предложения\n",
        "    for j, w in enumerate(text[i]):  # для каждого токена\n",
        "        if j >= MAX_LEN:\n",
        "            break\n",
        "        Y[i, j] = CHAR_TO_INDEX_Y.get(w, CHAR_TO_INDEX_Y['none'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqUrUpFRRAY6",
        "outputId": "b4575a03-2028-4385-f6b5-0cedf6c60ce8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 19,  4,  5,  7, 24, 25,  5, 16, 16, 29,  4, 13, 24,  4, 27,  5, 23,\n",
              "         4,  5,  4, 16, 13, 24, 24, 16,  9,  4, 19, 10,  4,  6, 19, 24, 12,  4,\n",
              "        23, 19, 17,  9, 24, 13, 17,  9, 23,  4, 27, 12,  9, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRLRKMGTRCWP",
        "outputId": "593a03d8-0c96-470d-b157-26d2fad17961"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([15, 16,  1,  2,  4, 21, 22,  2, 13, 13, 26,  1, 10, 21,  1, 24,  2, 20,\n",
              "         1,  2,  1, 13, 10, 21, 21, 13,  6,  1, 16,  7,  1,  3, 16, 21,  9,  1,\n",
              "        20, 16, 14,  6, 21, 10, 14,  6, 20,  1, 24,  9,  6, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "Y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9toGCkOm1oi"
      },
      "outputs": [],
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.embedding = torch.nn.Embedding(len(CHAR_TO_INDEX_X) + step, len(CHAR_TO_INDEX_X))\n",
        "        self.rnn = torch.nn.RNN(len(CHAR_TO_INDEX_X), 128)\n",
        "        self.out = torch.nn.Linear(128, len(CHAR_TO_INDEX_X) + step)\n",
        "\n",
        "    def forward(self, sentences, state=None):\n",
        "        x = self.embedding(sentences)\n",
        "        x, s = self.rnn(x) # берём выход с последнего слоя для всех токенов, а не скрытое состояние\n",
        "        return self.out(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6aCazQOm1oi"
      },
      "outputs": [],
      "source": [
        "model = Network()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmdNPJEWm1oj"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()  # типичный лосс многоклассовой классификации\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZEqmL7BR27s"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tXipgPNR3nk"
      },
      "outputs": [],
      "source": [
        "dataset = TensorDataset(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkD6ee3CSI2o"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwzvc-eqR_Ke"
      },
      "outputs": [],
      "source": [
        "iter = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0f_-cAdSR5N",
        "outputId": "5cfa84dd-29dd-41d1-95e8-61bddf2d6d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0. Time: 27.186, Train loss: 0.812\n",
            "Epoch 1. Time: 26.916, Train loss: 0.131\n",
            "Epoch 2. Time: 26.951, Train loss: 0.057\n",
            "Epoch 3. Time: 26.917, Train loss: 0.036\n",
            "Epoch 4. Time: 26.313, Train loss: 0.027\n"
          ]
        }
      ],
      "source": [
        "for ep in range(5):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_passed = 0\n",
        "\n",
        "    for x_in, y_in in iter:\n",
        "        x_in = x_in\n",
        "        y_in = y_in.view(1, -1).squeeze()\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model.forward(x_in).view(-1, len(INDEX_TO_CHAR) + step)\n",
        "\n",
        "        loss = criterion(y_pred, y_in)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1\n",
        "\n",
        "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O25R61QsWJXv"
      },
      "outputs": [],
      "source": [
        "def generate_sentence(word):\n",
        "    sentence = list(word)\n",
        "    sentence = [CHAR_TO_INDEX_Y.get(s, 0) for s in sentence]\n",
        "    answers = model.forward(torch.tensor(sentence))\n",
        "    probas, indices = answers.topk(1)\n",
        "    return ''.join([INDEX_TO_CHAR[ind.item()] for ind in indices.flatten()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4LE-oPhXWNQa",
        "outputId": "5de25a2b-2316-4b55-f79f-697c5c23f0fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello world'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "generate_sentence('khoorczruog')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV-9Sn3oaCLY"
      },
      "source": [
        "# **Задание 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzb3ClRLcA21"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = ''\n",
        "for i in phrases:\n",
        "  new_text += str(i)\n",
        "  new_text += ' '"
      ],
      "metadata": {
        "id": "KiK5Kci-pH9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "on6XeQqpp-X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = re.sub('[^a-z ]', ' ', new_text)\n",
        "new_text = re.sub('\\s+', ' ', new_text)"
      ],
      "metadata": {
        "id": "M0P9dNWAp8K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INDEX_TO_CHAR = sorted(list(set(new_text)))\n",
        "CHAR_TO_INDEX = {c: i for i, c in enumerate(INDEX_TO_CHAR)}"
      ],
      "metadata": {
        "id": "F93g_2LqpgrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHAR_TO_INDEX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkr0_6hspxgs",
        "outputId": "2bf61a4b-4718-403c-f2bf-d5b010193e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'a': 1,\n",
              " 'b': 2,\n",
              " 'c': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'f': 6,\n",
              " 'g': 7,\n",
              " 'h': 8,\n",
              " 'i': 9,\n",
              " 'j': 10,\n",
              " 'k': 11,\n",
              " 'l': 12,\n",
              " 'm': 13,\n",
              " 'n': 14,\n",
              " 'o': 15,\n",
              " 'p': 16,\n",
              " 'q': 17,\n",
              " 'r': 18,\n",
              " 's': 19,\n",
              " 't': 20,\n",
              " 'u': 21,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 24,\n",
              " 'y': 25,\n",
              " 'z': 26}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 40\n",
        "STEP = 3\n",
        "SENTENCES = []\n",
        "NEXT_CHARS = []\n",
        "for i in range(0, len(new_text) - MAX_LEN, STEP):\n",
        "    SENTENCES.append(new_text[i: i + MAX_LEN])\n",
        "    NEXT_CHARS.append(new_text[i + MAX_LEN])\n",
        "print('Num sents:', len(SENTENCES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1_t_jrZphIu",
        "outputId": "88f48a4c-6e1c-4a52-a7fb-e634c2e9391f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num sents: 2253060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Vectorization...')\n",
        "X = torch.zeros((len(SENTENCES), MAX_LEN), dtype=int)\n",
        "Y = torch.zeros((len(SENTENCES)), dtype=int)\n",
        "for i, sentence in enumerate(SENTENCES):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t] = CHAR_TO_INDEX[char]\n",
        "    Y[i] = CHAR_TO_INDEX[NEXT_CHARS[i]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFmHjPVjpmVE",
        "outputId": "953839e6-114a-45b4-9e46-cb74a9a97f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=512\n",
        "dataset = TensorDataset(X, Y)\n",
        "data = DataLoader(dataset, BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "Jn64Ac-ApnwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cYE4YpAaTDM"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.embedding = torch.nn.Embedding(dictionary_size, embedding_size)\n",
        "        self.hidden = torch.nn.RNN(embedding_size, num_hiddens, batch_first=True)\n",
        "        self.output = torch.nn.Linear(num_hiddens, num_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X)\n",
        "        _, state = self.hidden(out)\n",
        "        predictions = self.output(state[0].squeeze())\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgrteYyrbEXi"
      },
      "outputs": [],
      "source": [
        "def sample(preds):\n",
        "    softmaxed = torch.softmax(preds, 0)\n",
        "    probas = torch.distributions.multinomial.Multinomial(1, softmaxed).sample()\n",
        "    return probas.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_LbQrx6b4uY"
      },
      "outputs": [],
      "source": [
        "def generate_text():\n",
        "    start_index = random.randint(0, len(new_text) - MAX_LEN - 1)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = new_text[start_index: start_index + MAX_LEN]\n",
        "    generated += sentence\n",
        "\n",
        "    for i in range(MAX_LEN):\n",
        "        x_pred = torch.zeros((1, MAX_LEN), dtype=int)\n",
        "        for t, char in enumerate(generated[-MAX_LEN:]):\n",
        "            x_pred[0, t] = CHAR_TO_INDEX[char]\n",
        "\n",
        "        preds = model(x_pred.cuda()).cpu()\n",
        "        next_char = INDEX_TO_CHAR[sample(preds)]\n",
        "        generated = generated + next_char\n",
        "\n",
        "    print(generated[:MAX_LEN] + '|' + generated[MAX_LEN:])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(len(CHAR_TO_INDEX), 64, 128, len(CHAR_TO_INDEX))"
      ],
      "metadata": {
        "id": "u-XbWpvmrUyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "FFllK_SRr39Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSGW5gHfbse6"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()  # типичный лосс многоклассовой классификации\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)"
      ],
      "metadata": {
        "id": "wpfWp6OJ1lbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ep in range(20):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_passed = 0\n",
        "\n",
        "    model.train()\n",
        "    for X_b, y_b in data:\n",
        "        X_b, y_b = X_b.cuda(), y_b.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        answers = model(X_b)\n",
        "        loss = criterion(answers, y_b)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1\n",
        "\n",
        "    #scheduler.step()\n",
        "\n",
        "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
        "    model.eval()\n",
        "    generate_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwJSwRawryjs",
        "outputId": "fb95b363-a852-4c09-9f82-cb989005f651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0. Time: 28.292, Train loss: 2.302\n",
            "out boy its like looking into a living s|ouf thes in whow nis moner goop ontesfer\n",
            "Epoch 1. Time: 28.796, Train loss: 2.062\n",
            "eling oh man hell blow our winning strea|s the wive wise pages stontn nanles i al\n",
            "Epoch 2. Time: 28.371, Train loss: 1.970\n",
            " gift what could a girl have that i nan |nant naw gond and just in and the read c\n",
            "Epoch 3. Time: 28.345, Train loss: 1.909\n",
            " witnesses come in arthur now where did |entoutsers goo hirgigel coed mksivew mor\n",
            "Epoch 4. Time: 28.164, Train loss: 1.865\n",
            "your age im sure you understand things c|reatinf ficking and wouk the if fry hanc\n",
            "Epoch 5. Time: 27.967, Train loss: 1.830\n",
            " slack well how many should i get well w|e who pack who helcoute this i were olm \n",
            "Epoch 6. Time: 28.494, Train loss: 1.802\n",
            "ove at all we call those weekdays good o|f year pelpets fonits moithing becto bar\n",
            "Epoch 7. Time: 28.574, Train loss: 1.779\n",
            " looks the same it levels the playing fi|red mater up inach up look perolighte hi\n",
            "Epoch 8. Time: 28.361, Train loss: 1.759\n",
            "the gag oh forget it nan professor im um| if that phowars it aprabay a lunding og\n",
            "Epoch 9. Time: 28.205, Train loss: 1.742\n",
            " kid in my class by like two years for m|ake gous you amonent yeah duple like its\n",
            "Epoch 10. Time: 28.243, Train loss: 1.726\n",
            "still has my sweatshirt bongo didnt forg|s esser mine need they lottilal frows no\n",
            "Epoch 11. Time: 28.256, Train loss: 1.713\n",
            "ings for instance tonight im using a apu|st youre him forten if brottloss the mor\n",
            "Epoch 12. Time: 28.268, Train loss: 1.700\n",
            "alk but man can he rock say hello to the| marge theres wather like toop call you \n",
            "Epoch 13. Time: 28.358, Train loss: 1.689\n",
            " know what is it i dont know hes not my |ragethays aruuls long ioh the bazy sealv\n",
            "Epoch 14. Time: 28.322, Train loss: 1.680\n",
            " like knives nan big mistake attacking m|y but thats whated ils the enn our hapoo\n",
            "Epoch 15. Time: 28.327, Train loss: 1.671\n",
            "r geez homer this guy is bringin the who| got lone be tellod is come accal ad and\n",
            "Epoch 16. Time: 27.798, Train loss: 1.662\n",
            "e chief thats some good spelunking lou m|ise becoll i innlay give is alessiple fo\n",
            "Epoch 17. Time: 28.508, Train loss: 1.655\n",
            "this was her residence but all i see is |the only uh peepaming that dog dol cant \n",
            "Epoch 18. Time: 28.284, Train loss: 1.648\n",
            "hot dog sixty corncob two nan nan this i|n tlandey its whilfectake why didss well\n",
            "Epoch 19. Time: 28.213, Train loss: 1.641\n",
            " i lived on pi ata candy yeah well from |chared nan would i wauting a thant is is\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
